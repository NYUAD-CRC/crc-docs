A Detailed SLURM Guide
======================

SLURM: Partitions
-----------------

A partition is a collection of nodes, they may share some attributes (CPU type, GPU, etc)

* Compute nodes may belong to multiple partitions to ensure maximum use of the system
* Partitions may have different priorities and limits of execution and may limit who can use them
* Dalma's partition (as seen by users)

    * - **Partition**
      - **Description**
	* - ``compute``
      - General purpose partition for all the normal runs
	* - ``nvidia``
      - Partition of GPU jobs
	* - ``bigmem``
      - Partition for large memory jobs. Only jobs requesting more than 500GB will fall into this category.
	* - ``prempt``
      - Supports all types of jobs with a grace period of 30 minutes. More on this :ref:`here <preempt_partition>`
	* - ``xxl``
      - Special partition for grand challenge applications. Requires approval from management.
	* - ``visual``
      - We have a few nodes which give you the liberty of running applications with GUI.
      
* There are other partitions, but these are reserved for specific groups and research projects
* For those who are experts in SLURM we use partitions to request GPUs, large memory, and visual instead of "constraints" as this approach gives us more flexibility for priorities and resource limits.

SLURM: Submitting Jobs
----------------------

1. To submit a job first you write a "job script"

    .. code-block:: bash

        #!/bin/bash
        #SBATCH –n 1
        ./myprogram
2. Then you submit the script in any of the following manner

    .. code-block:: bash

        $> sbatch job.sh
        #OR
        $> sbatch < job.sh
        #OR
        $> sbatch << EOF
        #!/bin/bash
        #SBATCH –n 1
        ./myprogram
        EOF

SLURM: Arguments
----------------

* Arguments to ``sbatch`` can be put on the command line or embedded in the job script
* Putting them in the job script is a better option as then it "documents" how to rerun your job

.. code-block:: bash

    #!/bin/bash
    #SBATCH –n 1
    ./myprogram

.. code-block:: bash

    $> sbatch job1.sh

OR

.. code-block:: bash

    #!/bin/bash
    ./myprogram

.. code-block:: bash    

    $> sbatch –p preempt –n 1 job2.sh


**Common Job submission arguments:**

* ``-n``   Select number of tasks to run (default 1 core per task)
* ``-N``   Select number of nodes on which to run
* ``-t``   Wallclock in hours:minutes:seconds (ex 4:00:00)
* ``-p``   Select partition (serial, parallel, gpu, bigmem)
* ``-o``   Output file ( with no –e option, err and out are merged to the Outfile)
* ``-e``   Keep a separate error File
* ``-d``   Dependency with prior job (ex don't start this job before job XXX terminates)
* ``-A``   Select account (ex physics_ser, faculty_ser)
* ``-c``   Number of cores required per task (default 1)
* ``--tasks-per-node Number`` of tasks on each node
* ``--mail-type=type`` Notify on state change: BEGIN, END, FAIL or ALL
* ``--mail-user=user`` Who to send email notification
* ``--mem`` Maximum amount of memory per job (default is in MB, but can use GB suffix) (Note: not all memory is available to jobs, 8GB is reserved on each node for the OS) (So a 128GB node can allocate up to 120GB for jobs)


SLURM: Job Dependencies
-----------------------

Submitting with dependencies: Useful to create workflows

* Any specific job may have to wait until any of the specified conditions are met
* These conditions are set with –d type:jobid where type can be:
    * ``after``         run after <jobid> has terminated
    * ``afterany``      if <jobid> is a job array run after any job in the job array has terminated
    * ``afterok``       run after <jobid> if it finished successfully
    * ``afternotok``    run after <jobid> if it failed to finish successfully

.. code-block:: bash

    #Wait for specific job array elements	
    sbatch --depend=after:123_4 my.job
    sbatch --depend=afterok:123_4:123_8 my.job2	
    #Wait for entire job array to complete	
    sbatch --depend=afterany:123 my.job
    #Wait for entire job array to complete successfully	
    sbatch --depend=afterok:123 my.job
    #Wait for entire job array to complete and at least one task fails	
    sbatch --depend=afternotok:123 my.job

SLURM: Listing Jobs
-------------------

Each submitted job is given a unique number
* You can list your jobs to see which ones are waiting (pending), running
* As well as how long a job has been running and on which node(s)

.. code-block:: bash

    $> squeue
    JOBID           PARTITION   NAME     USER    ST  TIME    NODES   NODELIST(REASON)
    435251_[1-50]   compute     151215_F u123    PD  0:00      1        (Priority)
    435252_[1-50]   compute     151215_F u123    PD  0:00      1        (Priority)
    435294          compute     Merge5.s u123    PD  0:00      1        (Priority)
    435235_[20-50]  compute     151215_F u123    PD  0:00      1        (Priority)
    435235_19       compute     151215_F u123    R   12:55     1        compute-21-8
    435235_17       compute     151215_F u123    R   47:34     1        compute-21-12
    435235_15       compute     151215_F u123    R   49:04     1        compute-21-7
    435235_13       compute     151215_F u123    R   50:34     1        compute-21-4
    435235_11       compute     151215_F u123    R   54:35     1        compute-21-9
    435235_9        compute     151215_F u123    R   56:35     1        compute-21-6
    435235_7        compute     151215_F u123    R   58:35     1        compute-21-5
    435235_5        compute     151215_F u123    R   59:36     1        compute-21-1
    435235_3        compute     151215_F u123    R   1:00:36   1        compute-21-11
    435235_1        compute     151215_F u123    R   1:04:37   1        compute-21-3

SLURM: Listing Jobs
-------------------

* You can look at completed jobs using the "sacct" command
* To look at jobs you ran since July 1, 2017

.. code-block:: bash

    $> squeue –starttime=2017-07-01


* You can retrieve the following informations about a job after it terminates:

.. code-block:: bash

    AllocCPUS       Account        AssocID          AveCPU
    AveCPUFreq      AveDiskRead    AveDiskWrite     AvePages
    AveRSS          AveVMSize      BlockID          Cluster
    Comment         ConsumedEnergy CPUTime          CPUTimeRAW
    DerivedExitCode Elapsed        Eligible         End
    ExitCode        GID            Group            JobID
    JobName         Layout         MaxDiskRead      MaxDiskReadNode
    MaxDiskReadTask MaxDiskWrite   MaxDiskWriteNode MaxDiskWriteTask
    MaxPages        MaxPagesNode   MaxPagesTask     MaxRSS
    MaxRSSNode      MaxRSSTask     MaxVMSize        MaxVMSizeNode
    MaxVMSizeTask   MinCPU         MinCPUNode       MinCPUTask
    NCPUS           NNodes         NodeList         NTasks
    Priority        Partition      QOSRAW           ReqCPUFreq
    ReqCPUs         ReqMem         Reserved         ResvCPU
    ResvCPURAW      Start          State            Submit
    Suspended       SystemCPU      Timelimit        TotalCPU
    UID             User           UserCPU          WCKey


* To retrieve specific informations about a job

.. code-block:: bash

    $> sacct -j 466281 -format=partition,alloccpus,elapsed,state,exitcode
    JobID         JobName    Partition   Account   AllocCPUS  State     ExitCode
    ------------ ---------- ---------- ---------- ---------- ---------- --------
    466281        job3.sh     par_std   cpcm_par     56      COMPLETED    0:0
    466281.batch  batch                 cpcm_par     28      COMPLETED    0:0
    466281.0      env                   cpcm_par     56      COMPLETED    0:0

SLURM: Job Progress
-------------------

* You can see your job's progress by looking at the output and error files
* By default output and error files are named "slurm-XXX.out" and "slurm-XXX.err" where XXX is the job id
* "tail –f" allows you to track new output as it is produced

.. code-block:: bash

    $> cat slurm-435563.out
    $> more slurm-435563.out
    $> tail –f slurm-435563.out

SLURM: Killing Jobs
-------------------

* Sometimes you need to kill your job when you realise it is not working as expected
* Note that your job can be killed automatically when it reaches its maximum time/memory allocation
    
.. code-block:: bash

    $> scancel 435563

SLURM: Tasks
------------

In SLURM users specify how many tasks – not cores! - they need (-n). Each task by default
uses 1 core. But this can be redefined by users using the "-c" option.

For example ``#SBATCH –n 2`` is requesting 2 cores, while ``#SBATCH –c 3`` ``#SBATCH –n 2`` is
requesting 6 cores.

On Jubail/SLURM we implement an exclusive policy on nodes being used to run parallel jobs –
eg no other jobs may run on nodes allocated for running parallel jobs.

When submitting parallel jobs on Jubail you need not specify the number of nodes. The
number of tasks and cpus-per-task is sufficient for SLURM to determine how many nodes to
reserve.

SLURM: Node List
----------------

Sometimes applications require a list of nodes where they are to run in parallel to start.
SLURM keeps the list of nodes within the environment variable ``$SLURM_JOB_NODELIST``.

SLURM: Accounts
---------------

SLURM maintains user associations which include user, account, qos, and partition. Users
may have several associations. Moreover, accounts are hierarchical. For example, account
"physics" maybe be a sub-account of "faculty", which may be a sub-account of "institute", etc.
When submitting jobs users with multiple associations must explicitely list the account, qos,
partition details they wish to use.

.. code-block:: bash

    sbatch –p preempt –a physics -u ziaw job

Jubail specific job submission tools extend SLURM's associations to define a ``default``
association. So you only need to specify accounts is, for example, you belong to multiple
accounts – ex faculty and research-lab – and you want to execute using your non-default
account. So at most you'll need to specify:

.. code-block:: bash

    sbatch –p <partition> -a <account> job

Moreover, accounts, partitions, qos and users may each be configured with resource usage
limits. Thus the administrators can impose limits to the number of jobs queued, jobs running,
cores usage, and run time.

SLURM: Account Limits
---------------------

To see you SLURM associations (and their parents) as well as your resource usage limits use
the following Dalma specific tool:

.. code-block:: bash

    [ziaw@login-0-1 ~]$ slurm-show-my-limits.sh
    ---------- -------------------- -------------------- --------- ------- ------------- ------------- ------- --------- ----------- --------------------
        User              Account            Partition GrpSubmit GrpJobs       GrpTRES       MaxTRES MaxJobs MaxSubmit     MaxWall             Par Name
        ziaw             avengers                devel                                                   100       200
        ziaw             avengers               nvidia                   cpu=40,gres/+                   100       200
        ziaw         avengers_par              par_std                        cpu=2000      cpu=4000     100       200
        ziaw         avengers_ser              preempt                                                   100       200
        ziaw         avengers_ser               visual                                                   100       200
        ziaw         avengers_ser               bigmem                          cpu=32                   100       200
        ziaw         avengers_ser          preempt_std                                                   100       200
        ziaw         avengers_ser              ser_std                         cpu=200                   100       200
                        avengers                                                                        100       200                        institute
                        institute                                                                        100       200                            nyuad
                            nyuad                          20000    1000                                 100       200                             root
                            root
                    avengers_par                                                                        100       200                         avengers
                        avengers                                                                        100       200                        institute


**In this output we see:**

* user ``ziaw`` can submit up to 200 jobs on ``par_std`` (parallel) partition, but have at most 100 jobs running consuming a maximum of 700 cores total where each jobs is limited to a maximum of 200 cores for 12 hours
* user ``ziaw`` can submit up to 200 jobs on ``ser_std`` (serial) partition, with at most 100 jobs running using a total of up to 200 cores for up to 48 hours
* account ``avengers_par`` is shared with other users and together they have a limit of 2000 cores, 200 jobs queued, and 100 jobs running (eg the sum of all cores used by running jobs using account ``avengers_par`` can't exceed 2000 cores)
* account ``avengers_par`` is shared with other users and together they have a limit of 200 jobs queued, and 100 jobs running
* account ``avengers`` is a sub-account of ``nyuad`` and the sum of all parallel and serial jobs can't exceed 200 jobs queued, 100 jobs running

SLURM: Account Usage
--------------------

This next Dalma specific tool allows you to see how much resources you are using. This is useful when your
job can't run because of "group resource limit" having been reached.

You can view the usage with the command: ``slurm_show_usage``

.. code-block:: bash

    [ziaw@login-0-1 ~]$ slurm_show_usage -u u1234
    --------------------------------------------------------------------------------
    slurm_show_usage V1.0 - 2017 NYUAD Proprietary Software

    User line show the usage and limit for user=mfm15 within each account it belong.
    Account lines show the usage and limit for all users in that account.
    The indentation on Account lines represent the level of sub-accounts
    up to the present account.

    --------------------------------------------------------------------------------
    Usage  Limit     TYPE     Account
    --------------------------------------------------------------------------------
    672      1400  User     cpcm_par
    2296      5000  Account  cpcm_par
    2324      5000  Account      cpcm
    3754 UNLIMITED  Account          institute
    8103 UNLIMITED  Account              nyuad
    --------------------------------------------------------------------------------
        0        32  User     cpcm_ser
        28       280  Account  cpcm_ser
    2324      5000  Account      cpcm
    3754 UNLIMITED  Account          institute
    8103 UNLIMITED  Account              nyuad
    --------------------------------------------------------------------------------

* Here user ``u123`` has two accounts,``cpcm_par`` and ``cpcm_ser``. 
* On the ``cpcm_par`` (parallel partition) his limit is 1400 cores, and he's currently using 672 cores. 
* However, other users from the same account are already using 2296 cores out of the account maximum 5000.
* The ``cpcm_par`` account is a sub-account of ``cpcm``, which currently is using 2324 cores out of the 5000 permitted.
* The ``cpcm`` account is also a sub-account of ``institute``. All ``institute`` users are presently using 3754 cores out of the total cores account limit.
* Finally "institute" is a sub-account of ``nyuad`` where 8103 cores are being used.

The ``slurm_show_usage`` tool has an option to show you which account level would prevent you to run a job.

The ``-n 800`` option will show which
account(s) would exceed the user or
account core limit if you were to submit a
job requiring 800 cores.

.. image:: /hpc/img/slurm_show_usage.png

**The ``-a`` option will show all accounts usage and limit on Dalma, as well as their current usage.**

The usage limits are defined by the
academic steering committee in order to
meet each group's computational needs,
while allowing fairness to all groups.
The account limits are periodically revised
based on prior usage statistics and inputs
from the research groups about new
project requirements.

Thus, the HPC support team role is limited
to implementing the recommendations
from the steering committee and to provide
the steering committee with statistics and
other key informations that help them
define fair resource usage rules.

.. code-block:: bash

    --------------------------------------------------------------------------------
    slurm_show_usage V1.0 - 2017 NYUAD Proprietary Software

    Account lines show the usage and limit for all users in that account.
    The indentation on Account lines represent the level of sub-accounts
    up to the present account.



    --------------------------------------------------------------------------------
    Usage  Limit     TYPE     Account
    --------------------------------------------------------------------------------
    131       280  Account  physics_ser
    3099      4000  Account      physics
    4273 UNLIMITED  Account          faculty
    8093 UNLIMITED  Account              nyuad
    --------------------------------------------------------------------------------
    2968      3800  Account  physics_par
    3099      4000  Account      physics
    4273 UNLIMITED  Account          faculty
    8093 UNLIMITED  Account              nyuad
    --------------------------------------------------------------------------------

SLURM: System Usage
-------------------

**dmap**

The ``dmap`` tool (Dalma specific) will show you the utilization of each compute node on the cluster. The first
numbers is a shorthand for the compute node name, so ``12-3`` actually means ``compute-12-3``. The second
numbers represent the number of cores used and total number of cores in the system.
"white" highlight shows
nodes that are down for
maintenance.
"green" means a node is
busy.
No highlight means a
node is free.

You can launch this tool using the command ``dmap``

You can also check the different options available using the command ``dmap -h``

.. code-block:: bash

    [ziaw@login-0-1 ~]$ dmap -h

        Synopsis:
            Monitor utility to display in a compact mode, Dalma utilization as well as information about jobs and/or nodes

        Usage:
            dmap [ -b -l -m ] [ -u <users> ] [ -j <jobs> [ -i ]  ] [ -w <seconds> ] [ -c <columns> ] [ -x ] [-h]

            where:

            The following metrics can be displayed:

                -b: Show allocated resources as per the batch system (default)
                -l: Show actual cpu load in the nodes
                -m: Show Mem usage in the nodes

            and you can display the latter just for a specific set of jobs/users

                -u: Comma-separated list of users
                -j: Comma-separated list of jobs

                -i: Print Information about all jobs or a specific set of jobs if -j was specified

                -w: Wait and refresh after the specified number of seconds

                -x: Dump content in html for web visualization

                -c: Controls how many columns will display. Default is 9 because every 18 nodes are conected to the same linecard in the switches

                -h:  Prints out this helpful message

.. image:: /hpc/img/dmap.png

**SLURM Partition Monitor**

The ``slurm_partition_monitor`` tool gives a glimpse on the brief stats of difefrent resources in terms of partitions.

You can launch this tool using the command ``slurm_partition_monitor``

.. image:: /hpc/img/slurm_partition_monitor.png
